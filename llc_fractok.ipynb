{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fecb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from devinterp.optim import SGLD\n",
    "from devinterp.slt.sampler import estimate_learning_coeff_with_summary\n",
    "from devinterp.utils import plot_trace, default_nbeta\n",
    "\n",
    "from fractok import check_fractok\n",
    "from tracr.haiku_to_pytorch import haiku_to_pytorch\n",
    "\n",
    "\n",
    "from dataloaders import makeFractokDataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6d63c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = makeFractokDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e5a4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = check_fractok()\n",
    "torch_model = haiku_to_pytorch(model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93092611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, batch):\n",
    "    inputs, outputs = batch[0]  # Unpack from batch\n",
    "    \n",
    "    # inputs is already a list of strings like ['BOS', 'd', 'x', 'c', 'e']\n",
    "    # The model expects this format directly\n",
    "    \n",
    "    outputs = outputs.to(DEVICE)\n",
    "    \n",
    "    model_output = model.forward(inputs)  # Pass strings directly\n",
    "\n",
    "    if not model_output.is_cuda and DEVICE == \"cuda\":\n",
    "        model_output = model_output.to(DEVICE)\n",
    "\n",
    "    # if torch.isnan(sum(sum(sum(model_output)))):\n",
    "    #     print(inputs)\n",
    "    #     print(outputs)\n",
    "    #     print(model_output)\n",
    "\n",
    "    # print(\"Debug info:\")\n",
    "    # print(inputs[0], outputs[0], model_output[0])\n",
    "    loss = F.mse_loss(model_output, outputs) * 1000\n",
    "    # loss = F.cross_entropy(model_output, outputs)\n",
    "\n",
    "    return loss, {\n",
    "        \"logits\": model_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11482e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef8049c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc2e2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9676311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 101/101 [00:01<00:00, 74.95it/s]\n",
      "Chain 1: 100%|██████████| 101/101 [00:01<00:00, 94.17it/s]\n",
      "Chain 2: 100%|██████████| 101/101 [00:01<00:00, 96.25it/s]\n",
      "Chain 3: 100%|██████████| 101/101 [00:01<00:00, 98.96it/s]\n",
      "Chain 4: 100%|██████████| 101/101 [00:01<00:00, 99.34it/s]\n",
      "Chain 5: 100%|██████████| 101/101 [00:01<00:00, 99.13it/s]\n",
      "Chain 6: 100%|██████████| 101/101 [00:01<00:00, 95.90it/s]\n",
      "Chain 7: 100%|██████████| 101/101 [00:01<00:00, 98.58it/s]\n",
      "Chain 8: 100%|██████████| 101/101 [00:01<00:00, 97.04it/s]\n",
      "Chain 9: 100%|██████████| 101/101 [00:01<00:00, 98.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 101/101 [00:01<00:00, 98.12it/s]\n",
      "Chain 1: 100%|██████████| 101/101 [00:01<00:00, 87.40it/s]\n",
      "Chain 2: 100%|██████████| 101/101 [00:01<00:00, 96.62it/s]\n",
      "Chain 3: 100%|██████████| 101/101 [00:01<00:00, 99.55it/s]\n",
      "Chain 4: 100%|██████████| 101/101 [00:01<00:00, 99.46it/s]\n",
      "Chain 5: 100%|██████████| 101/101 [00:01<00:00, 93.22it/s]\n",
      "Chain 6: 100%|██████████| 101/101 [00:01<00:00, 97.77it/s]\n",
      "Chain 7: 100%|██████████| 101/101 [00:01<00:00, 99.50it/s]\n",
      "Chain 8: 100%|██████████| 101/101 [00:01<00:00, 99.28it/s]\n",
      "Chain 9: 100%|██████████| 101/101 [00:01<00:00, 99.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 101/101 [00:01<00:00, 98.96it/s]\n",
      "Chain 1: 100%|██████████| 101/101 [00:01<00:00, 75.68it/s]\n",
      "Chain 2: 100%|██████████| 101/101 [00:01<00:00, 98.63it/s]\n",
      "Chain 3: 100%|██████████| 101/101 [00:01<00:00, 95.85it/s]\n",
      "Chain 4:  90%|█████████ | 91/101 [00:00<00:00, 93.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m9\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     learning_coeff_stats = \u001b[43mestimate_learning_coeff_with_summary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSGLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalization\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_nbeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many independent chains to run\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_draws\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many samples to draw per chain\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many samples to discard at the beginning of each chain\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many steps to take between each sample\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43monline\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     trace = learning_coeff_stats[\u001b[33m\"\u001b[39m\u001b[33mloss/trace\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28msum\u001b[39m(learning_coeff_stats[\u001b[33m'\u001b[39m\u001b[33mllc/means\u001b[39m\u001b[33m'\u001b[39m])/\u001b[38;5;28mlen\u001b[39m(learning_coeff_stats[\u001b[33m'\u001b[39m\u001b[33mllc/means\u001b[39m\u001b[33m'\u001b[39m]), \u001b[32m2\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:164\u001b[39m, in \u001b[36mestimate_learning_coeff_with_summary\u001b[39m\u001b[34m(model, loader, callbacks, evaluate, sampling_method, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, init_loss, grad_accum_steps, cores, seed, device, gpu_idxs, verbose, optimize_over_per_model_param, online, use_amp)\u001b[39m\n\u001b[32m    154\u001b[39m     llc_estimator = LLCEstimator(\n\u001b[32m    155\u001b[39m         num_chains,\n\u001b[32m    156\u001b[39m         num_draws,\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m         init_loss=init_loss,\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m callbacks = [llc_estimator, *callbacks]\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_draws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_draws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize_over_per_model_param\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize_over_per_model_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpu_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m results = {}\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:369\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(model, loader, callbacks, evaluate, sampling_method, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, init_loss, grad_accum_steps, cores, seed, device, verbose, optimize_over_per_model_param, gpu_idxs, batch_size, use_amp, **kwargs)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chains):\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m         \u001b[43m_sample_single_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(callback, \u001b[33m\"\u001b[39m\u001b[33mfinalize\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:147\u001b[39m, in \u001b[36m_sample_single_chain\u001b[39m\u001b[34m(kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m loader = cloudpickle.loads(kwargs[\u001b[33m\"\u001b[39m\u001b[33mloader\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    146\u001b[39m kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickled_args}\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample_single_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:111\u001b[39m, in \u001b[36msample_single_chain\u001b[39m\u001b[34m(ref_model, loader, evaluate, optimizer_kwargs, num_draws, num_burnin_steps, num_steps_bw_draws, grad_accum_steps, sampling_method, chain, seed, verbose, device, optimize_over_per_model_param, callbacks, use_amp, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m data = prepare_input(data, device)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(\n\u001b[32m    109\u001b[39m     device_type=device.type, dtype=torch.float16, enabled=use_amp\n\u001b[32m    110\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     loss, results = split_results(results)\n\u001b[32m    114\u001b[39m     loss /= grad_accum_steps\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, batch)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# inputs is already a list of strings like ['BOS', 'd', 'x', 'c', 'e']\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# The model expects this format directly\u001b[39;00m\n\u001b[32m      7\u001b[39m outputs = outputs.to(DEVICE)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model_output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass strings directly\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_output.is_cuda \u001b[38;5;129;01mand\u001b[39;00m DEVICE == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     12\u001b[39m     model_output = model_output.to(DEVICE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/tracr/haiku_to_pytorch.py:74\u001b[39m, in \u001b[36mTracrTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# x: (batch, seq)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     x = torch.tensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.input_embeddings, dtype=torch.float64)\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# print(x.shape, x)\u001b[39;00m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/tracr/compiler/assemble.py:71\u001b[39m, in \u001b[36mAssembledTransformerModel.apply\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m     69\u001b[39m   tokens = \u001b[38;5;28mself\u001b[39m.input_encoder.encode(tokens)\n\u001b[32m     70\u001b[39m tokens = jnp.array([tokens])\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m decoded = output.unembedded_output[\u001b[32m0\u001b[39m].tolist()\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_encoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/multi_transform.py:315\u001b[39m, in \u001b[36mwithout_apply_rng.<locals>.apply_fn\u001b[39m\u001b[34m(params, *args, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_fn\u001b[39m(params, *args, **kwargs):\n\u001b[32m    314\u001b[39m   check_rng_kwarg(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/transform.py:183\u001b[39m, in \u001b[36mwithout_state.<locals>.apply_fn\u001b[39m\u001b[34m(params, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    177\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    178\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mIf the functions you are transforming use the same names you must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m out, state = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[32m    185\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m base.NonEmptyStateError(\n\u001b[32m    186\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mIf your transformed function uses `hk.\u001b[39m\u001b[33m{\u001b[39m\u001b[33mget,set}_state` then use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m`hk.transform_with_state`.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/transform.py:458\u001b[39m, in \u001b[36mtransform_with_state.<locals>.apply_fn\u001b[39m\u001b[34m(params, state, rng, *args, **kwargs)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m base.new_context(params=params, state=state, rng=rng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[32m    457\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m jax.errors.UnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m jax.errors.UnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/tracr/compiler/assemble.py:264\u001b[39m, in \u001b[36massemble_craft_model.<locals>.forward\u001b[39m\u001b[34m(emb)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;129m@hk\u001b[39m.without_apply_rng\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@hk\u001b[39m.transform\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(emb):\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m   compiled_model = \u001b[43mget_compiled_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m compiled_model(emb, use_dropout=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/tracr/compiler/assemble.py:249\u001b[39m, in \u001b[36massemble_craft_model.<locals>.get_compiled_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_compiled_model\u001b[39m():\n\u001b[32m    248\u001b[39m   transformer = model.Transformer(model_config)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m   embed_modules = \u001b[43m_make_embedding_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m      \u001b[49m\u001b[43mresidual_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresidual_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtokens_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokens_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m      \u001b[49m\u001b[43mindices_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m model.CompiledTransformerModel(\n\u001b[32m    255\u001b[39m       transformer=transformer,\n\u001b[32m    256\u001b[39m       token_embed=embed_modules.token_embed,\n\u001b[32m    257\u001b[39m       position_embed=embed_modules.pos_embed,\n\u001b[32m    258\u001b[39m       unembed=embed_modules.unembed,\n\u001b[32m    259\u001b[39m       use_unembed_argmax=categorical_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/tracr/compiler/assemble.py:195\u001b[39m, in \u001b[36m_make_embedding_modules\u001b[39m\u001b[34m(residual_space, tokens_space, indices_space, output_space)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# The zeroth position should not have any positional embeddings,\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# so we add one line of padding at the zeroth position.\u001b[39;00m\n\u001b[32m    193\u001b[39m pos_matrix = np.concatenate(\n\u001b[32m    194\u001b[39m     [np.zeros((\u001b[32m1\u001b[39m, residual_space.num_dims)), index_to_res.matrix], axis=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m pos_embed = \u001b[43mhk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbed\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpos_embed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munembed\u001b[39m(x, use_unembed_argmax):\n\u001b[32m    198\u001b[39m   out = x @ res_to_out.matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/module.py:141\u001b[39m, in \u001b[36mModuleMetaclass.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# We populate _auto_repr before `__init__` to allow `repr(self)` during the\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# constructor of the module.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (config.get_config().module_auto_repr \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mAUTO_REPR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m   module_repr = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauto_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    143\u001b[39m   module_repr = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__repr__\u001b[39m(module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/utils.py:88\u001b[39m, in \u001b[36mauto_repr\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Add varkwargs.\u001b[39;00m\n\u001b[32m     85\u001b[39m names_and_values.extend(\n\u001b[32m     86\u001b[39m     (name + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m, kwargs[name]) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m argspec.args)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m single_line = \u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnames_and_values\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(single_line) <= \u001b[32m80\u001b[39m:\n\u001b[32m     91\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m single_line\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/haiku/_src/utils.py:89\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Add varkwargs.\u001b[39;00m\n\u001b[32m     85\u001b[39m names_and_values.extend(\n\u001b[32m     86\u001b[39m     (name + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m, kwargs[name]) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m argspec.args)\n\u001b[32m     88\u001b[39m single_line = \u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     name + \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m names_and_values))\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(single_line) <= \u001b[32m80\u001b[39m:\n\u001b[32m     91\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m single_line\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:1610\u001b[39m, in \u001b[36m_array_repr_implementation\u001b[39m\u001b[34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[39m\n\u001b[32m   1608\u001b[39m     lst = \u001b[38;5;28mrepr\u001b[39m(arr.item())\n\u001b[32m   1609\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1610\u001b[39m     lst = \u001b[43marray2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_line_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[43m                       \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[38;5;66;03m# Add dtype and shape information if these cannot be inferred from\u001b[39;00m\n\u001b[32m   1614\u001b[39m \u001b[38;5;66;03m# the array string.\u001b[39;00m\n\u001b[32m   1615\u001b[39m extras = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:798\u001b[39m, in \u001b[36marray2string\u001b[39m\u001b[34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m a.size == \u001b[32m0\u001b[39m:\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m[]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:571\u001b[39m, in \u001b[36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m repr_running.add(key)\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    573\u001b[39m     repr_running.discard(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:604\u001b[39m, in \u001b[36m_array2string\u001b[39m\u001b[34m(a, options, separator, prefix)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# skip over array(\u001b[39;00m\n\u001b[32m    602\u001b[39m next_line_prefix += \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m * \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m lst = \u001b[43m_formatArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlinewidth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mnext_line_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43medgeitems\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msummary_insert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlegacy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lst\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:957\u001b[39m, in \u001b[36m_formatArray\u001b[39m\u001b[34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[39m\n\u001b[32m    953\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    956\u001b[39m     \u001b[38;5;66;03m# invoke the recursive part with an initial index and prefix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecurser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mhanging_indent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_line_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcurr_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    961\u001b[39m     \u001b[38;5;66;03m# recursive closures have a cyclic reference to themselves, which\u001b[39;00m\n\u001b[32m    962\u001b[39m     \u001b[38;5;66;03m# requires gc to collect (gh-10620). To avoid this problem, for\u001b[39;00m\n\u001b[32m    963\u001b[39m     \u001b[38;5;66;03m# performance and PyPy friendliness, we break the cycle:\u001b[39;00m\n\u001b[32m    964\u001b[39m     recurser = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:944\u001b[39m, in \u001b[36m_formatArray.<locals>.recurser\u001b[39m\u001b[34m(index, hanging_indent, curr_width)\u001b[39m\n\u001b[32m    941\u001b[39m         s += hanging_indent + summary_insert + line_sep\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trailing_items, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m     nested = \u001b[43mrecurser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hanging_indent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnext_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    946\u001b[39m     s += hanging_indent + nested + line_sep\n\u001b[32m    948\u001b[39m nested = recurser(index + (-\u001b[32m1\u001b[39m,), next_hanging_indent, next_width)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:910\u001b[39m, in \u001b[36m_formatArray.<locals>.recurser\u001b[39m\u001b[34m(index, hanging_indent, curr_width)\u001b[39m\n\u001b[32m    907\u001b[39m         line += separator\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trailing_items, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     word = \u001b[43mrecurser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hanging_indent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     s, line = _extendLine_pretty(\n\u001b[32m    912\u001b[39m         s, line, word, elem_width, hanging_indent, legacy)\n\u001b[32m    913\u001b[39m     line += separator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:861\u001b[39m, in \u001b[36m_formatArray.<locals>.recurser\u001b[39m\u001b[34m(index, hanging_indent, curr_width)\u001b[39m\n\u001b[32m    858\u001b[39m axes_left = a.ndim - axis\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axes_left == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformat_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[38;5;66;03m# when recursing, add a space to align with the [ added, and reduce the\u001b[39;00m\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# length of the line by 1\u001b[39;00m\n\u001b[32m    865\u001b[39m next_hanging_indent = hanging_indent + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/llc-interpretability/venv/lib/python3.12/site-packages/numpy/_core/arrayprint.py:1093\u001b[39m, in \u001b[36mFloatingFormat.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1094\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1095\u001b[39m             current_options = format_options.get()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for _ in range(9):\n",
    "    learning_coeff_stats = estimate_learning_coeff_with_summary(\n",
    "        torch_model,\n",
    "        loader=loader,\n",
    "        evaluate=evaluate,\n",
    "        sampling_method=SGLD,\n",
    "        optimizer_kwargs=dict(lr=1e-5, localization=1.0, nbeta=default_nbeta(loader)),\n",
    "        num_chains=10,  # How many independent chains to run\n",
    "        num_draws=100,  # How many samples to draw per chain\n",
    "        num_burnin_steps=1,  # How many samples to discard at the beginning of each chain\n",
    "        num_steps_bw_draws=1,  # How many steps to take between each sample\n",
    "        device=DEVICE,\n",
    "        online=True,\n",
    "    )\n",
    "    trace = learning_coeff_stats[\"loss/trace\"]\n",
    "    print(round(sum(learning_coeff_stats['llc/means'])/len(learning_coeff_stats['llc/means']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1091030",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trace(\n",
    "    trace,\n",
    "    \"Loss\",\n",
    "    x_axis=\"Step\",\n",
    "    title=f\"Loss Trace, avg LLC = {sum(learning_coeff_stats['llc/means']) / len(learning_coeff_stats['llc/means']):.2f}\",\n",
    "    plot_mean=False,\n",
    "    plot_std=False,\n",
    "    fig_size=(12, 9),\n",
    "    true_lc=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from torchinfo import summary\n",
    "# import itertools\n",
    "\n",
    "# # Define experiment parameters\n",
    "# max_seq_lens = [10, 50]\n",
    "# vocab_ranges = ['small', 'medium', 'large']\n",
    "# num_trials = 5\n",
    "\n",
    "# # Storage for results\n",
    "# results = []\n",
    "\n",
    "# total_configs = len(max_seq_lens) * len(vocab_ranges)\n",
    "# config_num = 0\n",
    "\n",
    "# # Run all combinations\n",
    "# for max_seq_len, vocab_range in itertools.product(max_seq_lens, vocab_ranges):\n",
    "#     config_num += 1\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Configuration {config_num}/{total_configs}: vocab={vocab_range}, max_seq_len={max_seq_len}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     # Create model and loader\n",
    "#     loader = makeFractokDataLoader(max_seq_len=max_seq_len, vocab_size=vocab_range)\n",
    "#     model = check_fractok(max_seq_len=max_seq_len, vocab_size=vocab_range)\n",
    "#     torch_model = haiku_to_pytorch(model).to(DEVICE)\n",
    "    \n",
    "#     # Get model info\n",
    "#     model_summary = summary(torch_model, verbose=0)\n",
    "#     num_params = model_summary.total_params\n",
    "#     num_blocks = len([m for m in torch_model.modules() if 'block' in str(type(m)).lower()])\n",
    "    \n",
    "#     print(f\"Model: {num_params} params, {num_blocks} blocks\")\n",
    "    \n",
    "#     # Convert vocab_range to readable format\n",
    "#     if vocab_range == 'small':\n",
    "#         vocab_str = 'a-e'\n",
    "#     elif vocab_range == 'medium':\n",
    "#         vocab_str = 'a-m'\n",
    "#     elif vocab_range == 'large':\n",
    "#         vocab_str = 'a-z'\n",
    "    \n",
    "#     # Run trials\n",
    "#     for trial in range(num_trials):\n",
    "#         print(f\"  Trial {trial + 1}/{num_trials}...\", end=\" \", flush=True)\n",
    "        \n",
    "#         learning_coeff_stats = estimate_learning_coeff_with_summary(\n",
    "#             torch_model,\n",
    "#             loader=loader,\n",
    "#             evaluate=evaluate,\n",
    "#             sampling_method=SGLD,\n",
    "#             optimizer_kwargs=dict(lr=1e-5, localization=1.0, nbeta=default_nbeta(loader)),\n",
    "#             num_chains=10,\n",
    "#             num_draws=100,\n",
    "#             num_burnin_steps=0,\n",
    "#             num_steps_bw_draws=1,\n",
    "#             device=DEVICE,\n",
    "#             online=True,\n",
    "#         )\n",
    "#         avg_llc = sum(learning_coeff_stats['llc/means']) / len(learning_coeff_stats['llc/means'])\n",
    "#         print(f\"LLC = {avg_llc:.4f}\")\n",
    "        \n",
    "#         # Append one row per trial\n",
    "#         results.append({\n",
    "#             'Average LLC': round(avg_llc, 4),\n",
    "#             'num_blocks': num_blocks,\n",
    "#             'num_params': num_params,\n",
    "#             'vocab': vocab_str,\n",
    "#             'max_input_size': max_seq_len\n",
    "#         })\n",
    "\n",
    "# # Create and display table\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"FINAL RESULTS\")\n",
    "# print(\"=\"*60)\n",
    "# df = pd.DataFrame(results)\n",
    "# df = df[['Average LLC', 'num_blocks', 'num_params', 'vocab', 'max_input_size']]\n",
    "\n",
    "# # Format to show 4 decimal places\n",
    "# pd.options.display.float_format = '{:.4f}'.format\n",
    "# print(df.to_string(index=False))\n",
    "\n",
    "# df.to_csv('fractok_results2.csv', index=False, float_format='%.4f')\n",
    "# print(\"\\nSaved to fractok_results2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
